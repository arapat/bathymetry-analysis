{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# READ IN ALL .tsv FILE PATHS AND ADD THEM TO THE LIST 'tsv_file_paths'\n",
    "\n",
    "tsv_file_paths = []\n",
    "for root, subdirs, files in os.walk(\"/geosat2/julaiti/tsv_all/SIO\"):\n",
    "    tsv_file_paths += [os.path.join(root, filename)\n",
    "                  for filename in files if filename.endswith(\"tsv\")]\n",
    "len(tsv_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = \"longitude latitude depth sigh sigd SID predicted_depth ID d10 d20 d60 seafloor_age curvature(VGG) spreading_rate sediment_thickness seafloor_roughness NDP_@2.5am NDP_@5am NDP_@10am NDP_@30am STD_@2.5am STD_@5am STD_@10am STD_@30am depth_SUB_median@2.5am depth_SUB_median@5am depth_SUB_median@10am depth_SUB_median@30am year data_type\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in tsv_file_paths:\n",
    "    # SET OUTPUT FILE NAME AS \"INPUT\".libsvm\n",
    "    svm_fn = filename.rsplit(\".\", 1)[0] + \".libsvm\"\n",
    "    \n",
    "    # OPEN THE TSV FILE\n",
    "    with open(filename) as fread:\n",
    "        # OPEN THE .libsvm FILE\n",
    "        with open(svm_fn, 'w') as fwrite:\n",
    "            for line in fread:\n",
    "                cols = line.strip().split()\n",
    "                if not cols:\n",
    "                    continue\n",
    "                label = (cols[4] == '9999')\n",
    "                cols = cols[:4] + cols[5:]\n",
    "                labels = [\"%d:%s\" % (i, v) for i, v in enumerate(cols) if v.lower() != \"nan\" and v != \"0\"]\n",
    "                fwrite.write(\"%d %s\\n\" % (label, ' '.join(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./all-done.txt\", 'w') as f:kk''\n",
    "    \n",
    "    \n",
    "    ]\n",
    "    f.write(\"done\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "libsvm_file_paths = []\n",
    "for root, subdirs, files in os.walk(\"./\"):\n",
    "    libsvm_file_paths += [os.path.join(root, filename)\n",
    "                  for filename in files if filename.endswith(\"libsvm\")]\n",
    "\n",
    "len(libsvm_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in all_files:\n",
    "    split = filename.rsplit(\"/\", 1)\n",
    "    new_dir = split[0] + \"_libsvm/\"\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.makedirs(new_dir)\n",
    "    os.rename(filename, new_dir + split[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(\"merge-files.sh\", 'w') as f:\n",
    "    for root, subdirs, files in os.walk(\"./\"):\n",
    "        t = [os.path.join(root, filename)\n",
    "             for filename in files if filename.endswith(\"libsvm\")]\n",
    "        if t:\n",
    "            command = \"cat %s > %s/data.libsvm\" % (' '.join(t), root)\n",
    "            f.write(command + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed individual files\n",
    "\n",
    "for root, subdirs, files in os.walk(\"./\"):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\"libsvm\") and filename != \"data.libsvm\":\n",
    "            os.remove(os.path.join(root, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "all_files = []\n",
    "for root, subdirs, files in os.walk(\"./\"):\n",
    "    all_files += [os.path.join(root, filename)\n",
    "                  for filename in files if filename == \"data.libsvm\"]\n",
    "\n",
    "len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from random import shuffle\n",
    "\n",
    "def shuffle_limited_memory(filename, ntest, nparts):\n",
    "    assert(ntest < nparts)\n",
    "    subfiles = [filename + \"_part%d\" % i for i in range(nparts)]\n",
    "    handlers = [open(name, 'w') for name in subfiles]\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            t = randint(0, nparts - 1)\n",
    "            handlers[t].write(line)\n",
    "    for handler in handlers:\n",
    "        handler.close()\n",
    "\n",
    "    base = filename.rsplit(\"/\", 1)[0]\n",
    "    training = open(base + \"/training.libsvm\", 'w')\n",
    "    testing = open(base + \"/testing.libsvm\", 'w')\n",
    "    shuffle(subfiles)\n",
    "    for i, name in enumerate(subfiles):\n",
    "        with open(name) as f:\n",
    "            lines = f.readlines()        \n",
    "        os.remove(name)\n",
    "        shuffle(lines)\n",
    "        s = ''.join(lines)\n",
    "        if not s.endswith('\\n'):\n",
    "            s += '\\n'\n",
    "        if i < ntest:\n",
    "            testing.write(s)\n",
    "        else:\n",
    "            training.write(s)\n",
    "    training.close()\n",
    "    testing.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in all_files:\n",
    "    print(filename)\n",
    "    shuffle_limited_memory(filename, 10, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in all_files:\n",
    "    old_dir, fname = filename.rsplit(\"/\", 1)\n",
    "    new_dir = old_dir + \"_data\"\n",
    "    os.mkdir(new_dir)\n",
    "    os.rename(filename, os.path.join(new_dir, fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(\"upload-s3.sh\", 'w') as f:\n",
    "    for root, subdirs, files in os.walk(\"./\"):\n",
    "        if root.endswith(\"_libsvm\"):\n",
    "            dirname = root[2:]\n",
    "            f.write(\"aws s3 cp {} s3://tmsn-data/bathymetry/{}/ --recursive\\n\".format(root, dirname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
